# -*- coding: utf-8 -*-
"""Bank marketing data.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1Sfn2rwdXr4XuJdcFognnhlHYCVOxl-EI
"""

# Get data to be still formated and readable
from google.colab import data_table
data_table.enable_dataframe_formatter()

# # Disable data frame formatter
# from google.colab import data_table
# data_table.disable_dataframe_formatter()

"""# Objective 

* Did EDA 
* Practice a machine learning program 
* How many rows and columns does the dataset contain?
* Are there any NaN values present?
* Are there any duplicate rows?
* What are the data types of the columns?
"""

# Import necessary libraries
import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt
import matplotlib as mpl
from sklearn.model_selection import train_test_split
mpl.rcParams['figure.figsize'] = (15,12)

# Read bank data
df = pd.read_csv('/content/drive/MyDrive/Project_Arfa_DS/bank_marketing_train.csv')
df

# Size
df.shape

df.columns

# Display head of data
df.head()

df.sample(5)

df.info()

"""# Descriptive analysis

* Define which columns have int/float and string datatype
* Rename y to term_deposit
* What is most frequent customer with marital status
* Check the target column that have categorical samples 
"""

df.describe()

# Check the categorical and numerical columns
num_col = df.select_dtypes(include='number')
cat_col = df.select_dtypes(include=object)

num_col.sample(5)

cat_col.sample(5)

# Rename column of y to term_deposit
df = df.rename(columns={'y':'term_deposit'})

column_names = ['age','education','housing']

# loop through the column names
for column_name in column_names:
    print(f"Unique values in column '{column_name}': {np.sort(df[column_name].unique())} {df[column_name].nunique()} unique values)")

print(f'In the target column, it is observed: \n {df["term_deposit"].value_counts()}')

"""# Data visualization

* Aim to : <br>
 a) Helps to understand the data, <br>
 b) Identify patterns and outliers, <br>
 c) Communicate findings, and inform further steps. 
"""

# Let visualize the target/label columns
ax = sns.countplot(data=df, 
                   x='term_deposit')
ax.set(xlabel='Bank term deposit as Yes and No',
       ylabel='Count of client',
       title='Client subscription preferences ')
plt.show()

bank_yes = df[df['term_deposit'] == 'yes']

# Columns of interest
columns = ['marital', 'month', 'job', 'education']
colors = ['red', 'green', 'blue', 'yellow']

# Create subplot
fig, axes = plt.subplots(nrows=2, ncols=2)

# Iterate through columns
for i, col in enumerate(columns):
    # Create crosstab
    ct = pd.crosstab(index=bank_yes[col], columns='count')
    # Plot crosstab as bar plot on subplot
    ct.plot.bar(ax=axes[i // 2, i % 2], color=colors[i]) 
    # Set title
    axes[i // 2, i % 2].set_title(col.upper())

"""# Find the missing values 


"""

# Check each element of data type 
df.applymap(type)

# Find missing values - affect performance of the model to produce accuarte result

# df.isna().sum()
print(f'Any NaN values among the data?\n {df.isna().values.any()}')

"""# Let's did some visualization

* Do age affect the acceptance rate on the marketing promotions
* Do education really affect the increasing of acceptance
"""

# Count customers of different age group
df['age'].value_counts().plot(kind='hist')
plt.title('Age distribution')
plt.show()

# Split data into training and test data
from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split(df[df[]])

